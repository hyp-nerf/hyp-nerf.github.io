<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork">
  <meta name="keywords" content="HyP-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork</h1>
          <h2 class="title is-3 publication-venue">NeurIPS 2023</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://bipashasen.github.io/">Bipasha Sen</a><sup>⭐ 1️⃣</sup>,</span>
              <span class="author-block">
                <a href="https://vanhalen42.github.io/">Gaurav Singh</a><sup>⭐ 1️⃣</sup>,</span>
              <span class="author-block">
                <a href="https://skymanaditya1.github.io/">Aditya Agarwal</a><sup>⭐ 1️⃣</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Ni6qG7wAAAAJ">Rohith Agaram</a><sup>1️⃣</sup>,
              </span><br>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=QDuPGHwAAAAJ">K. Madhava Krishna</a><sup>1️⃣</sup>,
              </span>
              <span class="author-block">
                <a href="https://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a><sup>2️⃣</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>⭐</sup>Equal Contribution,</span>
              <span class="author-block"><sup>1️⃣</sup>IIIT Hyderabad,</span>
              <span class="author-block"><sup>2️⃣</sup>Brown University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2306.06093.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
					<a href="https://arxiv.org/abs/2306.06093"
						class="external-link button is-normal is-rounded is-dark">
						<span class="icon">
							<i class="ai ai-arxiv"></i>
						</span>
						<span>arXiv</span>
					</a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
					<a href="https://youtu.be/KIDDsaA0Fis"
						class="external-link button is-normal is-rounded is-dark">
						<span class="icon">
							<i class="fab fa-youtube"></i>
						</span>
						<span>Video</span>
					</a>
				</span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/hyp-nerf/hyp-nerf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
              <a href="https://github.com/google/nerfies/releases/tag/0.1"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="far fa-images"></i>
                </span>
                <span>Data</span>
                </a>
            </span> -->
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
		<video id="teaser" autoplay muted loop playsinline height="100%">
		<source src="./static/videos/applications_teaser.mp4" type="video/mp4">
		</video>
		<h2 class="subtitle has-text-centered">
			<span class="dnerf">HyP-NeRF</span> learns a prior over implicit NeRF functions!
		</h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
	<div class="hero-body">
		<div class="container">
			<div id="results-carousel" class="carousel results-carousel">
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
					  	<source src="./static/videos/image2nerf2.mp4" type="video/mp4">
					</video>
				</div>
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
					  	<source src="./static/videos/text2nerf2.mp4" type="video/mp4">
					</video>
				</div>
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
					  	<source src="./static/videos/image2nerf3.mp4" type="video/mp4">
					</video>
				</div>
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
					  	<source src="./static/videos/image2nerf4.mp4" type="video/mp4">
					</video>
				</div>
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
					  	<source src="./static/videos/image2nerf5.mp4" type="video/mp4">
					</video>
				</div>
				<div class="item item-coffee">
					<video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/image2nerf1.mp4" type="video/mp4">
					</video>
				</div>
	
				<div class="item item-toby">
					<video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
						<source src="./static/videos/text2nerf1.mp4" type="video/mp4">
					</video>
				</div>
			</div>
			<br>
			<h2 class="subtitle has-text-centered">
				Generating NeRFs using HyP-NeRF from different queries in a single forward pass!
			</h2>
		</div>
	</div>
</section>

<section class="section">
	<div class="container is-max-desktop">
		<!-- Abstract. -->
		<div class="columns is-centered has-text-centered">
			<div class="column is-four-fifths">
				<h2 class="title is-3">Abstract</h2>
				<div class="content has-text-justified">
				<p>
					Neural Radiance Fields (NeRF) have become an increasingly popular representation to capture high-quality
					appearance and shape of scenes and objects. However, learning generalizable NeRF priors over categories of
					scenes or objects has been challenging due to the high dimensionality of network weight space.

					To address the limitations of existing work on generalization, multi-view consistency and to improve
					quality, we propose <span class="dnerf">HyP-NeRF</span>, a latent conditioning method for learning
					generalizable category-level NeRF priors using hypernetworks. Rather than using hypernetworks to estimate
					only the weights of a NeRF, we estimate both the weights and the multi-resolution hash encodings resulting
					in significant quality gains. To improve quality even further, we incorporate a denoise and finetune
					strategy that denoises images rendered from NeRFs estimated by the hypernetwork and finetunes it while
					retaining multiview consistency. These improvements enable us to use HyP-NeRF as a generalizable prior for
					multiple downstream tasks including NeRF reconstruction from single-view or cluttered scenes and
					text-to-NeRF. We provide qualitative comparisons and evaluate HyP-NeRF on three tasks: generalization,
					compression, and retrieval, demonstrating our state-of-the-art results.
				</p>
				</div>
			</div>
		</div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3" style="margin-bottom:-10px; z-index: 1; position: relative;">Approach</h2>
          <div class="content has-text-justified" style="position: relative; z-index: 0;">
            <video id="teaser" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/Approach.mp4" type="video/mp4">
            </video>
			<p>
				HyP-NeRF is a latent conditioning method for learning improved quality generalizable category-level NeRF priors using hypernetworks. Our hypernetwork is trained to generate the parameters of both, the multi-resolution hash encodings (MRHE) and weights of a NeRF model of a given category conditioned on an instance code. For each instance code, in the learned codebook, HyP-NeRF estimates an instance-specific MRHE along with the weights of an MLP. Our key insight is that estimating both the MRHEs and the weights results in a significant improvement in quality. To improve the quality even further, we denoise rendered views from the estimated NeRF model, and finetune the NeRF with the denoised images to enforce multiview consistency. This denoising and finetuning step significantly improves quality and fine details while retaining the original shape and appearance properties.
			</p>
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Architecture</h2>
          <div class="content has-text-justified" style="text-align: center!important;">
            <img src="./static/images/arch.jpg" width="80%" />
			<p style="text-align: left;">
			<b>Architectural Overview</b>: <span class="coolname">HyP-NeRF</span> is trained and inferred in two steps. In the first step <b>(top)</b>, our hypernetwork,
			<b>M</b> is trained to predict the parameters of a NeRF model, <b>f<sub>n</sub></b>corresponding to object
			instance <b>n</b>. At this stage, the NeRF model acts as a set of differentiable layers to compute the
			volumetric rendering loss, using which <b>M</b> is trained on a set of <i>N</i> objects, thereby learning
			a prior Φ = {Φ<sub>S</sub>, Φ<sub>C</sub>} over the shape and color codes given by <b>S</b> and <b>C</b>
			respectively. In the second step <b>(bottom)</b>, the quality of the predicted multiview consistent NeRF,
			<b>f<sub>n</sub></b> is improved using a denoising network trained directly in the image space. To do
			this, <b>f<sub>n</sub></b> is rendered from multiple known poses to a set of images that are improved to
			photorealistic quality. <b>f<sub>n</sub></b> is then finetuned on these improved images. Importantly,
			since <b>f<sub>n</sub></b> is only finetuned and not optimized from scratch, and thus <b>f<sub>n</sub></b>
			retains the multiview consistency whilst improving in terms of texture and shape quality.
			</p>
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="hero is-light is-small">
	<div class="hero-body">
		<div class="container">
			<h2 class="subtitle has-text-centered">
				HyP-NeRF can store thousands of NeRFs maintaining comparable quality against InstantNGP!
			</h2>
			<br>
			<div id="results-carousel" class="carousel results-carousel">
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression1.mp4" type="video/mp4">
					</video>
			  	</div>
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression2.mp4" type="video/mp4">
					</video>
			  	</div>
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression3.mp4" type="video/mp4">
					</video>
			  	</div>
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression1.mp4" type="video/mp4">
					</video>
			  	</div>
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression2.mp4" type="video/mp4">
					</video>
			  	</div>
				<div class="item item-steve">
					<video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
					  <source src="./static/videos/compression3.mp4" type="video/mp4">
					</video>
			  	</div>
			</div>
		</div>
	</div>
</section>

  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Additional Results</h2>
          <div class="content has-text-justified">
			
			<div class="item item-fullbody">
				<video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
				  	<source src="./static/videos/occgen1.mp4" type="video/mp4">
				</video>
		  	</div>

		  	<div class="item item-fullbody">
				<video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
					<source src="./static/videos/occgen2.mp4" type="video/mp4">
				</video>
	 		 </div>

            <div class="item item-fullbody">
              	<video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
                	<source src="./static/videos/denoise1.mp4" type="video/mp4">
              	</video>
            </div>

			<div class="item item-blueshirt">
                <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
                  	<source src="./static/videos/denoise2.mp4" type="video/mp4">
                </video>
            </div>
  
            <div class="item item-mask">
             	<video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
                	<source src="./static/videos/hyp_vs_naive.mp4" type="video/mp4">
              	</video>
            </div>

			<div class="item item-toby">
                <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
                  	<source src="./static/videos/inference_at_1024.mp4" type="video/mp4">
                </video>
            </div> 
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgements</h2>
      <p>This work was supported by NSF IIS #2143576, NSF CNS #2038897, an STTR Award from Traverse Inc., NSF CloudBank, and an AWS Cloud Credits award.</p>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{NEURIPS2023_a0303731,
 author = {Sen, Bipasha and Singh, Gaurav and Agarwal, Aditya and Agaram, Rohith and Krishna, Madhava and Sridhar, Srinath},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {51050--51064},
 publisher = {Curran Associates, Inc.},
 title = {HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a03037317560b8c5f2fb4b6466d4c439-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>. It is borrowing this <a
                href="https://github.com/nerfies/nerfies.github.io">source code</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  <div hidden="hidden">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=XFkX9yDAINaX-IcWo2Y1JPMQjMSlNo-z-isZSYW2_jo"></script>
  </div>
</body>
</html>
